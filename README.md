
# Round 1B Persona-Driven Document Intelligence System

## Overview
This solution addresses Adobe India Hackathon 2025 Round 1B:  
**"Connect What Matters - For the User Who Matters"**.  
Itâ€™s an intelligent document analyst that extracts and prioritizes relevant sections from PDF collections based on specific personas and their tasks.

---

## Approach

### ğŸ” Core Methodology

#### Persona Contextualization
- Combines persona role and job-to-be-done into a semantic query
- Uses **TF-IDF vectorization** to measure content relevance
- Prioritizes sections that best match the personaâ€™s needs

#### Hierarchical Content Analysis
- **Section Extraction**: Identifies headings and their hierarchy
- **Content Relevance**: Ranks sections by persona-task relevance
- **Granular Insights**: Extracts key sentences from top sections

#### Efficiency Optimizations
- Lightweight text processing (no large models)
- Efficient PDF parsing with PyMuPDF
- CPU-optimized operations

---

## ğŸ› ï¸ Processing Pipeline

```mermaid
graph TD
    A[Collection Folder] --> B[Read Persona/Job]
    B --> C[Process PDFs]
    C --> D[Extract Headings & Text]
    D --> E[Rank by Relevance]
    E --> F[Generate Output]
    F --> G[Save JSON Results]
```

---

## ğŸ“š Models and Libraries Used

### Core Libraries

| Library        | Version | Purpose                                      |
|----------------|---------|----------------------------------------------|
| PyMuPDF        | 1.24.4  | PDF text extraction and structure analysis   |
| scikit-learn   | 1.3.0   | TF-IDF vectorization, cosine similarity      |
| NLTK           | 3.8.1   | Tokenization and stopword filtering          |
| NumPy          | 1.24.3  | Numerical operations and matrix handling     |

---

## ğŸ§  Natural Language Processing

- **TF-IDF Vectorization**: For semantic similarity
- **NLTK Resources**:
  - Punkt Tokenizer
  - Stopwords
- **Text Preprocessing**:
  - Lowercasing
  - Special character removal
  - Stopword elimination
  - Tokenization

---

## ğŸ§° System Requirements

- Python 3.9+
- Docker
- CPU-only (no GPU)
- Model size â‰¤ 0 MB
- RAM â‰¥ 16 GB

---

## ğŸ“ Directory Structure

```
Challenge_1b/
â”œâ”€â”€ Collection 1 - Travel Planning/
â”‚   â”œâ”€â”€ PDFs/
â”‚   â”œâ”€â”€ challenge1b_input.json
â”‚   â””â”€â”€ challenge1b_output.json
â”œâ”€â”€ Collection 2 - Adobe Acrobat Learning/
â”‚   â”œâ”€â”€ PDFs/
â”‚   â”œâ”€â”€ challenge1b_input.json
â”‚   â””â”€â”€ challenge1b_output.json
â””â”€â”€ ...
```

---

## ğŸš€ How to Build and Run

### 1. ğŸ”§ Local Execution (Development)

#### Prerequisites

```powershell
pip install pymupdf scikit-learn nltk numpy
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

#### Running

```powershell
# Create input config
@'
{
  "persona": "Travel Planner",
  "job_to_be_done": "Plan a 4-day trip for 10 college friends to South of France"
}
'@ | Set-Content ".\Challenge_1b\Collection 1\challenge1b_input.json"

# Place PDFs in Collection 1\PDFs\
Copy-Item "path\to\*.pdf" ".\Challenge_1b\Collection 1\PDFs\"

# Run
python persona_document_analyzer.py
```

---

### 2. ğŸ³ Docker Execution (Production)

#### Build Docker Image

```powershell
docker build --platform linux/amd64 -t persona-doc-analyzer .
```

#### Run Container

```powershell
docker run --rm `
  -v ${PWD}/Challenge_1b:/app/Challenge_1b `
  --network none `
  persona-doc-analyzer
```

#### Expected Execution (Hackathon Format)

```bash
docker run --rm   -v ${pwd}/input:/app/input   -v ${pwd}/output:/app/output   --network none   mysolutionname:somerandomidentifier
```

---

## âœ… Output Validation

Check `challenge1b_output.json` in each collection folder:

- âœ… Metadata (persona, job, timestamp)
- âœ… Top 5 relevant sections
- âœ… Top 5 key sentences

---

## ğŸ’¡ Solution Features

- Persona-driven relevance detection
- Cross-document analysis
- Handles 3â€“10 PDFs in < 60 seconds
- Offline, CPU-only operation
- JSON output as per competition spec

---

## ğŸ“Œ Constraints Compliance

| Constraint           | Status         |
|----------------------|----------------|
| CPU-only             | âœ… No GPU used |
| Model size           | âœ… 0 MB         |
| Internet access      | âœ… Offline      |
| Runtime              | âœ… < 60s        |
| Platform             | âœ… AMD64        |

---

## ğŸ“¦ Test Case Examples

| Domain            | Persona             | Task Description                                 |
|------------------|----------------------|--------------------------------------------------|
| Travel Planning  | Travel Planner       | Plan trip to South of France                     |
| Business         | Investment Analyst   | Extract revenue trends from annual reports       |
| Education        | Chemistry Student    | Identify key concepts for exam prep              |

---

## ğŸ§¯ Troubleshooting

- âŒ PDFs missing â†’ Ensure correct folder (`Collection X/PDFs`)
- âŒ NLTK error â†’ Ensure `punkt` and `stopwords` are downloaded
- âŒ FileNotFoundError â†’ Check volume mounts and relative paths
- âŒ Invalid output â†’ Validate JSON against format

---

## ğŸš€ Competition Submission

- âœ… Git Repo (private)
- âœ… Dockerfile
- âœ… README (this file)
- âœ… Full Codebase in `persona_document_analyzer.py`

